# Equality of Opportunity (EOpp)

## EOpp Definition
Equality of opportunity is one of the most widely used definitions of fairness. For a recommender system, EOpp suggests that randomly chosen ``qualified'' candidates should be represented equally regardless of which group they belong to; in other words, the exposure of qualified candidates from any group should be equal. Most recommender systems generate scores <em>s(X)</em> (predicting the relevance of an item to a binary response variable <em>Y</em>) to rank candidate items based on a feature set <em>X</em>. In these cases, EOpp corresponds to the independence of <<em>s(X)</em> and characteristic/attribute <em>C</em> given the response/label <em>Y=1</em>, i.e.

![P(s(X) \leq t \mid C= c_1, Y=1) = P(s(X) \leq t \mid C= c_2, Y=1),\forall c_1, c_2.](https://render.githubusercontent.com/render/math?math=P(s(X)%20%5Cleq%20t%20%5Cmid%20C%3D%20c_1%2C%20Y%3D1)%20%3D%20P(s(X)%20%5Cleq%20t%20%5Cmid%20C%3D%20c_2%2C%20Y%3D1)%2C%5Cforall%20c_1%2C%20c_2.)

## EOpp Algorithm
We provide the post-processing technique presented in *[Nandy et al. (2021)](https://arxiv.org/abs/2006.11350)*. The function <code>eOppTransformation()</code> (see [EOppUtils](lift/src/main/scala/com/linkedin/lift/mitigation/EOppUtils.scala)) can be used to learn a transformation that can be applied to model scores for achieving EOpp. The distribution of the transformed scores can be forced to match as the distribution before transformation by setting the argument <code>originalScale = true</code>. This is useful for blending the transformed scores <em>s<sup>\*</sup>(X)</em> with the original scores <em>s(X)</em> as <em>t \* s<sup>\*</sup>(X) + (1-t) \* s(X)</em> to achieve a fairness-performance trade-off by adjusting the tuning parameter <em>t</em> in [0, 1].

## Position bias adjustment
To define EOpp in the presence of the position bias, we need to take into account the dependency of the response variable <em>Y</em> on the position where the item is shown. To this end, we denote the counterfactual response when an item appears at position <em>j</em> by <em>Y(j)</em>. Furthermore, we use <img src="https://render.githubusercontent.com/render/math?math=%5Cgamma"> to denote the position of an item in the ranking generated by <em>s(X)</em>. Therefore, the observed response is given by <em>Y(<img src="https://render.githubusercontent.com/render/math?math=%5Cgamma">)</em>.

A scoring function <em>s(X)</em> of a recommendation system satisfies EOpp with respect to a characteristic <em>C</em> if
![P(s(X) \leq t \mid C=c_1,Y(\gamma)=1) = P(s(X) \leq t \mid C=c_2,Y(\gamma)=1), \forall t, c_1, c_2.](https://render.githubusercontent.com/render/math?math=P(s(X)%20%5Cleq%20t%20%5Cmid%20C%3Dc_1%2CY(%5Cgamma)%3D1)%20%3D%20P(s(X)%20%5Cleq%20t%20%5Cmid%20C%3Dc_2%2CY(%5Cgamma)%3D1)%2C%20%5Cforall%20t%2C%20c_1%2C%20c_2.)

We provide a debiasing technique that should be applied before applying the EOpp algorithm in the presence of position bias. The function <code>debiasPositiveLabelScores()</code> (see [positionBiasUtils](lift/src/main/scala/com/linkedin/lift/lib/positionBiasUtils.scala)) removes the effect of the position bias from the training data and the output can be directly used by <code>eOppTransformation()</code> (see [EOppUtils](lift/src/main/scala/com/linkedin/lift/mitigation/EOppUtils.scala)) for learning the EOpp transformation.

## Example
We illustrate the position bias adjusted EOpp algorithm in [EOppUtilsTest](lift/src/Test/scala/com/linkedin/lift/mitigation/EOppUtilsTest.scala). 

<strong>Data Generation</strong> (as in *[Nandy et al. (2021)](https://arxiv.org/abs/2006.11350)*): We generate a population of <em>p</em> = 50,000 items, where each item consists of id <em>i</em>, characteristic <em>C<sub>i</sub></em> in {0, 1}, label at position 1 <em>Y<sub>i</sub>(1)</em> and relevance <em>R<sub>i</sub></em>. We independently generate <em>C<sub>i</sub></em>'s from a <em>Bernoulli(0.6)</em> distribution. The conditional distribution <em>Y<sub>i</sub>(1)</em> given <em>C<sub>i</sub> = 0</em> is <em>Bernoulli(0.4)</em>, and the conditional distribution <em>Y<sub>i</sub>(1)</em> given <em>C<sub>i</sub> = 0</em> is <em>Bernoulli(0.5)</em>. Finally, <em>R<sub>i</sub></em> | <em>(C<sub>i</sub>, Y<sub>i</sub>(1))</em> is generated from 
<em>Gaussian(0.6Y<sub>i</sub>(1) + 2C<sub>i</sub>, 0.5) + (1 - C<sub>i</sub>) \* Uniform[0,~ (1 + Y<sub>i</sub>(1))]</em>.

We consider a recommendation system with <em>K</em> = 50 slots. For each session, we randomly select 50 items from the population and assign a score <em>s<sub>i</sub> = R<sub>i </sub> + Gaussian(0, 0.1)</em> to each selected item <em>i</em> = 1,..., 50000. The selected items are then ranked according to <em>s<sub>i</sub></em> (in a descending order) and assigned position according to <em>rank(i)</em>. Finally, the item <em>i</em> at position <em>j</em> gets observed response <em>Y(j) = Y(1) \* Bernoulli(w<sub>j</sub>)</em> with position bias <em>w<sub>j</sub> = 1 /</em> log<sub>2</sub><em>(1+j)</em>. 

<strong>Validation</strong>: We learn the EOpp transformation using [training data](lift/src/Test/Data/TrainingData.csv) containing 20K i.i.d.\ sessions (i.e. 20K * 50 = 1M samples). For testing, we apply the transformation on [validation data](lift/src/Test/Data/TrainingData.csv) containing 20000 i.i.d.\ sessions. To apply the effect of position bias in the transformed validation data, we multiply the labels <em>Y(1)</em> with Bernoulli(1/(1 + position)) random numbers, where the position corresponds to the rank of an item according to the transformed score. We validate the EOpp transformation by computing the 2nd Wasserstein distance between the transformed positive label score distributions corresponding to <em>C=0</em> and <em>C=1</em>. Additionally, we validate the equality of the transformed score distribution and the scores before the transformation.

